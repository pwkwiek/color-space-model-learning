{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1129f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import DEVICE\n",
    "from data_loader import get_dataloaders\n",
    "from models import get_model\n",
    "from training import train_in_stages\n",
    "from colorspace import convert_and_normalize\n",
    "\n",
    "from analysis.precompute import compute_all_analysis_outputs\n",
    "from analysis.plots_full import run_all_full_plots\n",
    "from analysis.summary import build_summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0affdb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# EXPERIMENT SETTINGS\n",
    "# -------------------------------\n",
    "\n",
    "DATASET = \"CIFAR10\"        # \"CIFAR10\", \"HAM10000\", \"KANSAS\"\n",
    "MODEL_TYPE = \"resnet18\"   # \"mediumcnn\", \"shallowcnn\", \"efficientnet\"\n",
    "\n",
    "COLOR_SPACES = [\"rgb\", \"lab\", \"hsv\", \"yuv\", \"ycrcb\", \"xyz\"]\n",
    "\n",
    "EPOCHS_TOTAL = 20\n",
    "FIRST_STAGE_EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 32\n",
    "\n",
    "print(f\"Dataset: {DATASET}\")\n",
    "print(f\"Model: {MODEL_TYPE}\")\n",
    "print(f\"Color spaces: {COLOR_SPACES}\")\n",
    "\n",
    "train_loader, val_loader, test_loader, CLASS_NAMES, class_weights = \\\n",
    "    get_dataloaders(DATASET, batch_size=BATCH_SIZE, img_size=IMG_SIZE)\n",
    "\n",
    "print(\"Classes:\", CLASS_NAMES)\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# TRAIN MODELS FOR EACH COLOR SPACE\n",
    "# -------------------------------\n",
    "\n",
    "results = {}\n",
    "models_by_space = {}\n",
    "\n",
    "for space in COLOR_SPACES:\n",
    "    print(\"\\n==========================================\")\n",
    "    print(f\"Training for color space: {space.upper()}\")\n",
    "    print(\"==========================================\")\n",
    "\n",
    "    model = get_model(MODEL_TYPE, num_classes=len(CLASS_NAMES))\n",
    "\n",
    "    stats = train_in_stages(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        test_loader=test_loader,\n",
    "        first_stage_epochs=FIRST_STAGE_EPOCHS,\n",
    "        final_epochs=EPOCHS_TOTAL,\n",
    "        color_space=space,\n",
    "        class_weights=class_weights,\n",
    "    )\n",
    "\n",
    "    results[space] = stats\n",
    "    models_by_space[space] = model\n",
    "\n",
    "print(\"\\n Training completed for all color spaces!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eefe435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# RUN ALL ANALYSIS IN ONE CALL\n",
    "# -------------------------------\n",
    "import importlib\n",
    "import analysis.gradcam as gradcam\n",
    "importlib.reload(gradcam)\n",
    "\n",
    "import analysis.precompute as precompute\n",
    "importlib.reload(precompute)\n",
    "\n",
    "import analysis.plots_full as plots_full\n",
    "importlib.reload(plots_full)\n",
    "\n",
    "import analysis.precompute as precompute\n",
    "importlib.reload(precompute)\n",
    "from analysis.precompute import compute_all_analysis_outputs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "analysis_outputs = compute_all_analysis_outputs(\n",
    "    models_by_space=models_by_space,\n",
    "    results=results,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_spaces=COLOR_SPACES,\n",
    "    convert_fn=convert_and_normalize,\n",
    ")\n",
    "\n",
    "color_complexity = analysis_outputs[\"color_complexity\"]\n",
    "texture_complexity = analysis_outputs[\"texture_complexity\"]\n",
    "confusions              = analysis_outputs[\"confusions\"]\n",
    "per_class_acc           = analysis_outputs[\"per_class_acc\"]\n",
    "embedding_stability     = analysis_outputs[\"embedding_stability\"]\n",
    "color_complexity        = analysis_outputs[\"color_complexity\"]\n",
    "texture_complexity      = analysis_outputs[\"texture_complexity\"]\n",
    "color_sensitivity       = analysis_outputs[\"color_sensitivity\"]\n",
    "kernel_stats_by_space   = analysis_outputs[\"kernel_stats\"]\n",
    "kernel_similarity_to_rgb= analysis_outputs[\"kernel_similarity\"]\n",
    "complexity_metrics      = analysis_outputs[\"complexity_metrics\"]\n",
    "pruning_sensitivity     = analysis_outputs[\"pruning_sensitivity\"]\n",
    "gcam_iou_to_rgb         = analysis_outputs[\"gcam_iou\"]\n",
    "attention_entropy       = analysis_outputs[\"attention_entropy\"]\n",
    "feature_redundancy      = analysis_outputs[\"feature_redundancy\"]\n",
    "deltaE_stats_all        = analysis_outputs[\"deltaE_stats\"]\n",
    "ssim_stats_all          = analysis_outputs[\"ssim_stats\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88642309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# PLOTS (CORE + FULL)\n",
    "# -------------------------------\n",
    "\n",
    "run_all_full_plots(\n",
    "    results,\n",
    "    COLOR_SPACES,\n",
    "    CLASS_NAMES,\n",
    "    confusions,\n",
    "    per_class_acc,\n",
    "    embedding_stability,\n",
    "    color_complexity,\n",
    "    texture_complexity,\n",
    "    color_sensitivity,\n",
    "    kernel_stats_by_space,\n",
    "    kernel_similarity_to_rgb,\n",
    "    complexity_metrics,\n",
    "    pruning_sensitivity,\n",
    "    gcam_iou_to_rgb,\n",
    "    attention_entropy,\n",
    "    feature_redundancy,\n",
    "    models_by_space,\n",
    "    test_loader,\n",
    "    gradcam_sample_indices=(0, 5, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = build_summary_table(\n",
    "    color_spaces=COLOR_SPACES,\n",
    "    results=results,\n",
    "    analysis_outputs=analysis_outputs,\n",
    ")\n",
    "\n",
    "summary_df.to_csv(\"results/summary_table_full_metrics.csv\", index=False)\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69908c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colorspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
